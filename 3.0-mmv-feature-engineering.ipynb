{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for filesizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from train_test_cv_split import read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing train-test-cv split and verifying the distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path():\n",
    "    NOTEBOOK_PATH=os.getcwd()\n",
    "    PROJECT_ROOT=os.path.dirname(NOTEBOOK_PATH)\n",
    "    return PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT=get_path()\n",
    "OUTPUT_PATH_TRAIN=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"train\")\n",
    "OUTPUT_PATH_TEST=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"test\")\n",
    "OUTPUT_PATH_CV=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"cv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=pd.read_csv(os.path.join(OUTPUT_PATH_TRAIN,\"X_train.csv\"))\n",
    "X_test=pd.read_csv(os.path.join(OUTPUT_PATH_TEST,\"X_test.csv\"))\n",
    "X_cv=pd.read_csv(os.path.join(OUTPUT_PATH_CV,\"X_cv.csv\"))\n",
    "y_train=pd.read_csv(os.path.join(OUTPUT_PATH_TRAIN,\"y_train.csv\"))\n",
    "y_test=pd.read_csv(os.path.join(OUTPUT_PATH_TEST,\"y_test.csv\"))\n",
    "y_cv=pd.read_csv(os.path.join(OUTPUT_PATH_CV,\"y_cv.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FqbIWSJMyRK1Ni7tVAuO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jh371q0WXKwZP8gynubU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JLrOfGem93RVtBySioNx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dSkI7FWjpnhwJABYgT4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2fJyCR49hpGrWIZ7F6tH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Id\n",
       "0  FqbIWSJMyRK1Ni7tVAuO\n",
       "1  jh371q0WXKwZP8gynubU\n",
       "2  JLrOfGem93RVtBySioNx\n",
       "3  dSkI7FWjpnhwJABYgT4s\n",
       "4  2fJyCR49hpGrWIZ7F6tH"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path():\n",
    "    NOTEBOOK_PATH=os.getcwd()\n",
    "    PROJECT_ROOT=os.path.dirname(NOTEBOOK_PATH)\n",
    "    return PROJECT_ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_byte_size(id):\n",
    "    file=f\"{id}.txt\"\n",
    "    PROJECT_ROOT=get_path()\n",
    "    BYTES_FILE_PATH=os.path.join(PROJECT_ROOT,\"data\",\"interim\",\"byteFiles\")\n",
    "    statinfo=os.stat(os.path.join(BYTES_FILE_PATH,file))\n",
    "    return round(statinfo.st_size/(1024.0*1024.0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_asm_size(id):\n",
    "    file=f\"{id}.asm\"\n",
    "    PROJECT_ROOT=get_path()\n",
    "    ASM_FILE_PATH=os.path.join(PROJECT_ROOT,\"data\",\"interim\",\"asmFiles\")\n",
    "    statinfo=os.stat(os.path.join(ASM_FILE_PATH,file))\n",
    "    return round(statinfo.st_size/(1024.0*1024.0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features=X_train.copy()\n",
    "X_test_features=X_test.copy()\n",
    "X_cv_features=X_cv.copy()\n",
    "\n",
    "X_train_features['BYTE_SIZE']=X_train_features.map(append_byte_size)\n",
    "X_test_features['BYTE_SIZE']=X_test_features.map(append_byte_size)\n",
    "X_cv_features['BYTE_SIZE']=X_cv_features.map(append_byte_size)\n",
    "X_train_features['ASM_SIZE']=X_train_features['Id'].map(append_asm_size)\n",
    "X_test_features['ASM_SIZE']=X_test_features['Id'].map(append_asm_size)\n",
    "X_cv_features['ASM_SIZE']=X_cv_features['Id'].map(append_asm_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constansts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT=get_path()\n",
    "FEATURE_EXTRACTION_OUTPUT_PATH=os.path.join(PROJECT_ROOT,\"data\",\"processed\")\n",
    "TRAIN_OUTPUT_FILE=os.path.join(FEATURE_EXTRACTION_OUTPUT_PATH,\"train\",\"Byte_Asm_File_sizes.csv\")\n",
    "TEST_OUTPUT_FILE=os.path.join(FEATURE_EXTRACTION_OUTPUT_PATH,\"test\",\"Byte_Asm_File_sizes.csv\")\n",
    "CV_OUTPUT_FILE=os.path.join(FEATURE_EXTRACTION_OUTPUT_PATH,\"cv\",\"Byte_Asm_File_sizes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features.to_csv(TRAIN_OUTPUT_FILE,index=False)\n",
    "X_test_features.to_csv(TEST_OUTPUT_FILE,index=False)\n",
    "X_cv_features.to_csv(CV_OUTPUT_FILE,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting F:\\Microsoft Malware Detection\\src\\features\\feature_eng_file_sizes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"F:\\Microsoft Malware Detection\\src\\features\\feature_eng_file_sizes.py\"\n",
    "\n",
    "#Importing requrired libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from train_test_cv_split import read_data\n",
    "\n",
    "## Performing train-test-cv split and verifying the distribution of classes\n",
    "def get_path():\n",
    "    NOTEBOOK_PATH=os.getcwd()\n",
    "    PROJECT_ROOT=os.path.dirname(NOTEBOOK_PATH)\n",
    "    return PROJECT_ROOT\n",
    "PROJECT_ROOT=get_path()\n",
    "OUTPUT_PATH_TRAIN=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"train\")\n",
    "OUTPUT_PATH_TEST=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"test\")\n",
    "OUTPUT_PATH_CV=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"cv\")\n",
    "\n",
    "\n",
    "X_train=pd.read_csv(os.path.join(OUTPUT_PATH_TRAIN,\"X_train.csv\"))\n",
    "X_test=pd.read_csv(os.path.join(OUTPUT_PATH_TEST,\"X_test.csv\"))\n",
    "X_cv=pd.read_csv(os.path.join(OUTPUT_PATH_CV,\"X_cv.csv\"))\n",
    "y_train=pd.read_csv(os.path.join(OUTPUT_PATH_TRAIN,\"y_train.csv\"))\n",
    "y_test=pd.read_csv(os.path.join(OUTPUT_PATH_TEST,\"y_test.csv\"))\n",
    "y_cv=pd.read_csv(os.path.join(OUTPUT_PATH_CV,\"y_cv.csv\"))\n",
    "## Feature Extraction\n",
    "\n",
    "def get_path():\n",
    "    NOTEBOOK_PATH=os.getcwd()\n",
    "    PROJECT_ROOT=os.path.dirname(NOTEBOOK_PATH)\n",
    "    return PROJECT_ROOT\n",
    "\n",
    "def append_byte_size(id):\n",
    "    file=f\"{id}.bytes\"\n",
    "    PROJECT_ROOT=get_path()\n",
    "    BYTES_FILE_PATH=os.path.join(PROJECT_ROOT,\"data\",\"interim\",\"byteFiles\")\n",
    "    statinfo=os.stat(os.path.join(BYTES_FILE_PATH,file))\n",
    "    return round(statinfo.st_size/(1024.0*1024.0),2)\n",
    "\n",
    "def append_asm_size(id):\n",
    "    file=f\"{id}.asm\"\n",
    "    PROJECT_ROOT=get_path()\n",
    "    ASM_FILE_PATH=os.path.join(PROJECT_ROOT,\"data\",\"interim\",\"asmFiles\")\n",
    "    statinfo=os.stat(os.path.join(ASM_FILE_PATH,file))\n",
    "    return round(statinfo.st_size/(1024.0*1024.0),2)\n",
    "\n",
    "X_train_features=X_train.copy()\n",
    "X_test_features=X_test.copy()\n",
    "X_cv_features=X_cv.copy()\n",
    "\n",
    "X_train_features['BYTE_SIZE']=X_train_features.map(append_byte_size)\n",
    "X_test_features['BYTE_SIZE']=X_test_features.map(append_byte_size)\n",
    "X_cv_features['BYTE_SIZE']=X_cv_features.map(append_byte_size)\n",
    "X_train_features['ASM_SIZE']=X_train_features['Id'].map(append_asm_size)\n",
    "X_test_features['ASM_SIZE']=X_test_features['Id'].map(append_asm_size)\n",
    "X_cv_features['ASM_SIZE']=X_cv_features['Id'].map(append_asm_size)\n",
    "\n",
    "## Writing the output\n",
    "### Constansts\n",
    "\n",
    "PROJECT_ROOT=get_path()\n",
    "FEATURE_EXTRACTION_OUTPUT_PATH=os.path.join(PROJECT_ROOT,\"data\",\"processed\")\n",
    "TRAIN_OUTPUT_FILE=os.path.join(FEATURE_EXTRACTION_OUTPUT_PATH,\"Byte_Asm_File_sizes_train.csv\")\n",
    "TEST_OUTPUT_FILE=os.path.join(FEATURE_EXTRACTION_OUTPUT_PATH,\"Byte_Asm_File_sizes_test.csv\")\n",
    "CV_OUTPUT_FILE=os.path.join(FEATURE_EXTRACTION_OUTPUT_PATH,\"Byte_Asm_File_sizes_cv.csv\")\n",
    "\n",
    "X_train_features.to_csv(TRAIN_OUTPUT_FILE,index=False)\n",
    "X_test_features.to_csv(TEST_OUTPUT_FILE,index=False)\n",
    "X_cv_features.to_csv(CV_OUTPUT_FILE,index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
