
from sklearn.feature_extraction.text import CountVectorizer
from tqdm import tqdm
from scipy.sparse import csr_matrix,vstack

def bytes_unigram_extraction(files,vocab):
    vocab_len=len(vocab)
    total_byte_files_len=len(files)
    vectorizer=CountVectorizer(ngram_range=(1,1))
    vectorizer.fit_transform(vocab)
    unigram=[]
    for file_name_idx in tqdm(range(total_byte_files_len)):
        with open(files[file_name_idx]+'.txt','r') as temp:
            all_lines=temp.read().replace("\n"," ").replace("  "," ").lower()
            unigram_temp=vectorizer.transform([all_lines])
            unigram.append(unigram_temp)
    unigram=vstack(unigram)
    return unigram
